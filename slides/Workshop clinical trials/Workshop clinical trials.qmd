---
title: "Introductory Statistics in Clinical Research"
subtitle: "With a special focus on biosimilar research"
author: "Thomas Debray, PhD"
format: revealjs
engine: knitr
---

# Introduction

## What is epidemiology?

Study the occurrence of illness and its relationship to determinants

- Diagnosis
- Etiology (causes)
- Prognosis
- Treatment of disease

## The role of study design

1. Theoretical design
2. Design of data collection
3. Design of data analysis

## Theoretical design

Formulating the research question in terms of

- Domain: target population

::: {style="font-size: 0.7em"}
  e.g., Adults with relapsing–remitting multiple sclerosis
:::

- Determinants

::: {style="font-size: 0.7em"}
  e.g., Treatment with dimethyl fumarate
:::


- Outcome

::: {style="font-size: 0.7em"}
e.g., Impairement as measured using the Expanded Disability Status Scale
:::

## Design of Data Collection

Prospective

- Data are yet to be collected and recorded for both outcome and determinants when the study is started 

Retrospective

- Data were recorded in the past and are collected after the study is initiated
- Prone to missing data 
- Prone to recall bias

Combinations of retrospective and prospective data collection can occur. 


## Design of Data Collection

**Issue #1**: Time between collection of determinant and outcome information

a. Cross-sectional design: data on determinant and outcome are measured simultaneously

    - e.g., a study to estimate the prevalence of relapsing-remitting multiple sclerosis at one point in time
    - e.g., a study to characterize the first symptoms of multiple sclerosis in patients diagnosed with multiple sclerosis

b. Longitudinal design: outcome variables are measured over time

    - e.g., a randomized clinical trial to investigate the efficacy and safety of dimethyl fumarate as compared with placebo in patients with relapsing–remitting multiple sclerosis (doi: 10.1056/NEJMoa1206328)

## Design of Data Collection

**Issue #2**: Selection of study participants

Census

- All patients with a certain condition are followed for some time to monitor the development of the outcome
- e.g., a registry study to investigate treatment persistence and disability follow-up in consecutive patients with relapsing-remitting multiple sclerosis (doi: <span style="color:blue;">10.1136/jnnp-2018-319831</span>) 

## Design of Data Collection

**Issue #2**: Selection of study participants

Simple random sampling

::: {style="font-size: 0.9em"}
- Rather than examining the entire population (census), an equally informative subgroup of the population is studied. 
- Every subject has an equal chance of being selected for the study
- Distribution of determinants in the sample will reliably reflect the distributions in the population experience from whom the sample was drawn
- e.g., a national survey to investigate health outcomes and lifestyle in people with multiple sclerosis 
:::

## Design of Data Collection

**Issue #2**: Selection of study participants

Simple random sampling

::: {style="font-size: 0.9em"}
- Randomly select study participants within certain strata/subgroups of the population
- e.g., a case-control study where researchers recruit incident MS cases from a registry and subsequently construct a random sample of “control” individuals who are similar to the cases but do not have MS. The two groups are then compared with respect to historical determinants (e.g., sleep duration and sleep quality)
- Another example, randomization will be stratified based on region or disease history (treatment naïve or not), body weight (common for PK study) and other factor main potentially influence the study measurements.
:::

## Design of Data Collection

**Issue #2**: Selection of study participants

Non-probability sampling

- Study participants are selected based on the subjective judgement of the researcher, rather than random selection
- e.g., Randomized clinical trials that are based on convenience samples from selected hospitals, including only patients with strict characteristics

## Design of Data Collection

**Issue #3**: Experimental versus non-interventional (observational) research

![](Picture 1.png){width=100%}

## Design of Data Collection

**Issue #3**: Experimental versus non-interventional (observational) research

::: {style="font-size: 0.8em"}
- The term ‘trial’ implies an element of experimentation and a prospective approach in the collection of data, whereas a ‘study’ is a systematic assessment of events that unfold without interfering with their course. 
- A non-interventional trial may be interpreted as “a study where the medicinal product(s) is (are) prescribed independent to inclusion of the patient in the study and as part of a therapeutic strategy, including diagnostic and monitoring procedures, which is not decided in advance by a study protocol but is applied according to the current clinical practice”
:::

::: {style="font-size: 0.5em"}
Source: European Network of Centres for Pharmacoepidemiology and Pharmacovigilance. ENCePP considerations on the definition of non-interventional trials under the current legislative framework [<span style="color:blue;">ref</span>]
:::

## Design of Data Collection

Examples of non-interventional studies

::: {style="font-size: 0.9em"}
- A cross-sectional study to characterize the first symptoms of MS
- A survey to investigate health outcomes in people with MS
- A post-authorization safety study (PASS) to assess to evaluate the safety and benefit-risk profile of natulizumab as prescribed in routine clinical practice
- A drug utilization study (DUS) using registry data to investigate patterns of the usage of medicines in routine clinical practice
- A registry study to investigate treatment persistence and disability follow-up in consecutive patients with relapsing-remitting multiple sclerosis (doi: <span style="color:blue;">10.1136/jnnp-2018-319831</span>) 
:::

## Design of Data Collection

Examples of experimental clinical trials

- A phase III clinical trial to investigate the efficacy and safety of dimethyl fumarate as compared with placebo in patients with relapsing–remitting multiple sclerosis (doi: <span style="color:blue;">10.1056/NEJMoa1206328</span>)
- A single-arm study where all participants are assigned to receive the experimental intervention after which their results are compared to the patient’s history

## Common study designs

![](Picture 2.png){width=100%}

::: {style="font-size: 0.5em"}
NIS: Non-interventional study; EXP: experimental study
:::

# Experimental clinical Trials

## Background

Key characteristics

- Prospective experiment of medical intervention(s)
- Aim is to measure the intervention effect on prognosis
- Exposure groups differ only by intervention(s) of interest
- Patients are allocated to the intervention, do not choose it

## Background

Key design features

- Inclusion and exclusion criteria
- Control group
- Randomisation
- Blinding

## Eligibility criteria

Need to specify which participants are recruited

- Balance the advantages and disadvantages of having a highly selected group against those associated with including a wide variety of subjects
- Narrow eligibility criteria tends to increase statistical power as similar subjects are more likely to respond to the treatment in a similar manner, but increases the difficulty of the recruitment.
- Wide eligibility criteria tends to increase generalizability of trial results

## Control group

To what reference should the experimental treatment be compared (if any)?

- Placebo control
- Active control
- Uncontrolled
- Historical control

Drugs with no efficacy can seem impressive in uncontrolled trials (e.g. due to placebo effect)

## Randomization

Randomization evenly distributes measured and unmeasured factors among intervention groups

::: {style="font-size: 0.8em"}
- Each subject has the same chance of being allocated to any treatment group
- The only systematic difference between the study arms should be the treatment given
- Any differences in results observed at the end of the trial should be due to the effect of the new treatment, and not to any other factors 
- Avoids bias and confounding
:::

=> Randomization facilitates identification of causal relationships

## Blinding

::: {style="font-size: 0.8em"}
Aim: to conceal the trial intervention given to each subject

Subjects or researchers may have expectations associated with a particular treatment. This may affect the data integrity:

- How patients respond to treatment, regarding both efficacy and safety profile.
- How the researcher manages or assesses the subject


It is generally recommended to blind the subject and anyone involved in giving the treatment, or managing or assessing the subject (double-blinded)
:::

## Trial design

Parallel group design

::: {style="font-size: 0.8em"}
- Patients are each randomised to ONE of the treatment arms
- The results from the 2 (or more) groups are compared at the end of the trial
- Used when treatments have long-lasting effects
- Recommended approach for phase III trials
:::

![](Picture 3.png){width=100% fig-align="center"}


## Trial design

Crossover design

::: {style="font-size: 0.8em"}
- Instead of randomly allocating subjects to treatment arms, the ordering of treatments is random
- Washout between treatment periods 
- Each subject is their own control (eliminates between-subject variability)
- Fewer patients needed
- Not suitable to investigate long-term outcomes (e.g., safety)
- Often used in phase I trials that include a control group
:::

## Trial design

![](Picture 4.png){width=100%}


## Phases

Four main types of clinical trials

![](Picture 5.png){width=100%}


# Phase 1 trials

![](Picture 6.png){width=100%}


## Phase I trial

Typical objectives

- Exploratory
- To determine the pharmacologic and metabolic effects in healthy volunteers

    - Pharmacodynamics (**PD**): physical or biological measures that show the effect of the new drug on the body
    - Pharmacokinetics (**PK**): physical or biological measures that show how the body deals with the new drug.
    
- To detect the most common side effects

## Phase I trial

Key endpoints: PK parameters

- Area under the curve (AUC): quantify total drug exposure
- $C_{max}$ : The highest concentration level
- $T_{max}$ : The time at which $C_{max}$ occurs
- $t_{1/2}$ : terminal half-life, the time it takes for the plasma concentration to decrease by 50% in the final part of the curve, when the drug is being eliminated

## Example of a phase I trial (NCT01884935)

::: {style="font-size: 0.9em"}
- Population

    - Pediatric patients with secondary progressive MS

- Interventions

    - Natalizumab 300 mg every 4 weeks for 16 weeks (𝑁=13)

- Outcomes: 

    - Maximum plasma concentration ($C_{max}$) of natalizumab
    - Minimum observed concentration ($C_{min}$) of natalizumab
    - Time to maximum observed concentration ($T_{max}$) of natalizumab
    - Area under the concentration-time curve from time zero to infinity ($AUC_{inf}$) of natalizumab
    - …
:::

## Example of a phase I trial (NCT01884935)

![](Picture 7.png){width=100%}


## Example of a phase I trial (NCT01884935)

![](Picture 8.png){width=100%}


# Phase 2 trials

![](Picture 9.png){width=100%}

## Phase II trial

::: {style="font-size: 0.9em"}
Key characteristics

- Aim is to obtain a preliminary estimate of efficacy, and/or to determine the optimal dose
- Emphasis on safety and intermediate outcomes
- Randomization is possible but not essential

Example

- A randomized, blinded, parallel-group, phase 2 study exploring the safety, tolerability, and efficacy of multiple regimens of Natalizumab in adult subjects with relapsing MS.
:::

## Example of a phase II trial (NCT01405820)

::: {style="font-size: 0.8em"}
- Population

    - Patients with relapsing-remitting MS
    
- Interventions

    - Natalizumab 300 mg intravenous (IV) every 4 weeks for 60 weeks (<span style="color:red;">𝑁=54</span>)
    - Natalizumab 300 mg subcutaneous (SC)every 4 weeks for 60 weeks (<span style="color:red;">𝑁=45</span>)
    - Natalizumab 300 mg IV every 12 weeks for 60 weeks (<span style="color:red;">𝑁=52</span>)
    - Natalizumab 300 mg SC every 12 weeks for 60 weeks (<span style="color:red;">𝑁=54</span>)
    - Natalizumab 150 mg IV every 12 weeks for 60 weeks (<span style="color:red;">𝑁=47</span>)
    - Natalizumab 150 mg SC every 12 weeks for 60 weeks (<span style="color:red;">𝑁=38</span>)

- Outcomes

    - Cumulative number of combined unique active lesions
:::


# Phase 3 trials

![](Picture 10.png){width=100%}


## Phase III trial

Key characteristics

- Aim is to obtain a definitive estimate of efficacy
- Investigation of *clinically relevant* outcomes
- Randomization is required
- Commonly implemented to obtain a marketing licence (“pivotal trial”)

## Example of a phase III trial (NCT00027300)

::: {style="font-size: 0.8em"}
A 2:1 randomized placebo-controlled trial to determine the safety and efficacy of natalizumab in the treatment of individuals with relapsing multiple sclerosis.

- Population

    - Patients with relapsing-remitting MS

- Intervention(s)

    - Natalizumab 300 mg IV infusion, every 4 weeks, for up to 116 weeks (<span style="color:red;">𝑁=627</span>)

- Comparator(s)

    - Placebo, IV infusion, every 4 weeks, for up to 116 weeks (<span style="color:red;">𝑁=315</span>)

- Outcomes

    - Cumulative probability of sustained progression of disability at 2 years
    - Annualized rate of relapse
:::

## Example of a phase III trial (NCT00027300)

Eligibility criteria

::: {style="font-size: 0.7em"}
"Enrollment was limited to men and women who were between the ages of 18 and 50 years and had a diagnosis of relapsing multiple sclerosis; who had a score of 0 to 5.0 on the Expanded Disability Status Scale (EDSS), a rating that ranges from 0 to 10, with higher scores indicating more severe disease; who had undergone magnetic resonance imaging (MRI) showing lesions consistent with multiple sclerosis; and who had had at least one medically documented relapse within the 12 months before the study began. Patients with disease that was categorized as primary progressive, secondary progressive, or progressive relapsing were excluded. Additional exclusion criteria included the following: a relapse within 50 days before the administration of the first dose of the study drug, treatment with cyclophosphamide or mitoxantrone within the previous year, or treatment with interferon beta, glatiramer acetate, cyclosporine, azathioprine, methotrexate, or intravenous immune globulin within the previous 6 months. Patients who had received treatment with interferon beta, glatiramer acetate, or both for more than six months were also excluded."
:::

::: {style="font-size: 0.5em"}
**Ref**: Polman CH, et al. A Randomized, Placebo-Controlled Trial of Natalizumab for Relapsing Multiple Sclerosis. N Engl J Med. 2006 Mar 2;354(9):899–910.
:::

## Example of a phase III trial (NCT00027300)

![](Picture 11.png){width=100%}


## Example of a phase III trial (NCT00027300)

![](Picture 12.png){width=100%}


# Phase 4 trials

![](Picture 13.png){width=100%}


## Phase IV trial

Key characteristics

- Aim is to study rare side effects or subgroup of patients and “real-world” effectiveness once the new treatment has been adopted into routine clinical practice
- Also known as post-marketing or surveillance studies
- Commonly involves investigation of patient-reported outcomes

## Example of a phase IV trial (NCT00871780)

::: {style="font-size: 0.9em"}
A prospective, open-label, non-randomized clinical trial to determine if natalizumab improves ambulatory measures in relapsing-remitting MS patients.

- Population

    - Patients with relapsing-remitting MS

- Intervention(s)

    - Natalizumab 300 mg IV every 4 weeks for 48 weeks (<span style="color:red;">𝑁= 224</span>)

- Outcomes

    - Change From Baseline in the Timed 100-meter Walk Test
    - Change From Baseline in the Timed 25-foot Walk Test
    - Change From Baseline in Maximum Walking Distance
    - Change From Baseline in Expanded Disability Status Scale
:::

## Example of a phase IV trial (NCT00871780)

![](Picture 14.png){width=100%}


## Summary

![](Picture 15.png){width=100%}


# Analysis of clinical trials

Experimental clinical Trials

## Estimation of treatment effect

In randomized clinical trials, we can quantify the treatment effect of drug A (active) versus drug B (control) as follows:

![](Picture 16.png){width=100%}
 
## Estimation of treatment effect
 
![](Picture 17.png){width=100%}


## Estimation of treatment effect

If the data are assumed to be normally distributed, an approximate 95% confidence interval is given by <span style="color:blue;">Mean ± (SD/sqrt(n)*1.96)</span>

![](Picture 18.png){width=100%}


## Formal testing of treatment effects

Hypothesis test to evaluate the difference between two (or more) drugs

- $𝐻_0$  : Null hypothesis
- $𝐻_1$ : Alternative hypothesis
- Aim is to reject $𝐻_0$

We assume that $𝐻_0$  is true and subsequently determine the likelihood of the observed data. This results in a p-value (= the probability that an effect as large as that observed, or more if $𝐻_0$ is true)

## Formal testing of treatment effects

Interpretation of p-values

- P-values < 0.05 provide evidence to reject $𝐻_0$ (and usually indicate that drug A is superior / non-inferior / equivalent to drug B)
- P-values > 0.05 indicate that there is not enough evidence to reject $𝐻_0$ (which does not necessarily mean that $𝐻_0$ is true)

![](Picture 19.png){width=100% fig-align="center"}


## Formal testing of treatment effects

Possible reasons for p>0.05

- There really is no difference
- There is a real difference, but by chance the sample of subjects did not show this
- There is a real difference, but the trial had too few subjects, and therefore insufficient power, to detect it.

Absence of evidence ≠ evidence of absence

## Formal testing of treatment effects

![](Picture 20.png){width=100%}


## Formal testing of treatment effects

![](Picture 21.png){width=100%}


## Formal testing of treatment effects

![](Picture 22.png){width=100%}


## Formal testing of treatment effects

::: {style="font-size: 0.9em"}
Determination of a clinically meaningful difference $\delta$

- Different choice of 𝛿 may affect the sample size calculation
- The margin $\delta$ should be based on both statistical reasoning and clinical judgment

    - Previous placebo-controlled trials similar to those planned for the new trial (ICH 10 guideline)
    - Systematic literature review
    - Limits proposed by FDA and/or EMA (e.g., bioequivalence trials)

- One of the most controversial subjects in drug development
:::

## Errors when testing hypotheses

- There is a chance that we incorrectly fail to reject $𝐻_0$
- There is a chance that we incorrectly reject $𝐻_0$
- The chance of error needs to be controlled

![](Picture 23.png){width=100%}

## Type I error

![](Picture 24.png){width=100%}


## Type II error

![](Picture 25.png){width=100%}


## Controlling type I and type II errors

![](Picture 26.png){width=100%}


## Confidence intervals

![](Picture 27.png){width=100%}


## Sample size estimation

![](Picture 28.png){width=100%}


## Sample size estimation

![](Picture 29.png){width=100%}


# Clinical trials for biosimilars

## Introduction

A biosimilar medicine is a biological medicine that is developed to be highly similar and clinically equivalent to an existing medicine.

::: {style="font-size: 0.8em"}
- A biosimilar contains a version of an active substance of an already approved biological medicine, which is referred to as the ‘<span style="color:red;"> reference medicine</span>’.
- Similarity to the reference medicine must be established based on a comprehensive biosimilar comparability exercise, such that they do not have any clinically meaningful differences from the reference medicine in terms of quality, biological activity, safety, efficacy and immunogenicity.
:::

## Introduction

A biosimilar is not regarded as a generic of a biological medicine.

::: {style="font-size: 0.7em"}
- This is mostly because the natural variability and more complex manufacturing of biological medicines do not allow an exact replication of the molecular microheterogeneity.
- Consequently, more studies are needed for regulatory approval of biosimilars than for generics to ensure that minor differences do not affect safety or efficacy.
:::

## Introduction

![](Picture 30.png){width=100%}


## Clinical Development Plan (CDP)

![](Picture 31.png){width=100%}


# Phase 1 biosimilar trials

![](Picture 32.png){width=100%}


## Clinical Development Plan

**Phase I**

- Randomized to 2-3 arms including the reference product(s)
- Need to <span style="color:green;">prove</span> the bio-equivalence of PK parameters
- Requires larger sample size than phase I trials of innovative drugs
- Blinded sample size re-assessment is often needed
- Recommend parallel design other than cross-over design from FDA.

## Examples

![](Picture 33.png){width=100%}


HV = Healthy volunteers

* The reference product was studied in 2 separate arms: one US-sourced drug and one EU-sourced drug

## Pharmacokinetic parameters

The trial should demonstrate bio-equivalence for various PK parameters

- Area under the blood or plasma concentration–time curve (AUC)
- Maximum concentration Cmax
- …

::: {style="font-size: 0.5em"}
**Ref**: Committee for medicinal products for human use (CHMP). Guideline on the investigation of bioequivalence. London, UK: European Medicines Agency; 2010 Jan. Report No.: CPMP/EWP/QWP/1401/98. 
:::

## Requirements for hypothesis testing

- Hypothesis testing should be based on the ratio of the population geometric means 
- The 90% confidence interval for the ratio of the test and reference products should be contained within the acceptance interval of 80.00 to 125.00%. 
- A margin of clinical equivalence (∆) is chosen by defining the largest difference that is clinically acceptable, so that a difference bigger than this would matter in practice. 
- The data should be transformed prior to analysis using a logarithmic transformation and subsequently be analyzed using ANOVA

::: {style="font-size: 0.5em"}
**Ref**: Committee for medicinal products for human use (CHMP). Guideline on the investigation of bioequivalence. London, UK: European Medicines Agency; 2010 Jan. Report No.: CPMP/EWP/QWP/1401/98. 
:::

## Hypothesis test for PK parameters

::: {style="font-size: 0.7em"}
Consider a PK parameter that follows a log-normal distribution (e.g., $C_{max}$ or AUC)

We can assess equivalence by testing the following hypothesis:

- **Null hypothesis**: the drugs are not equivalent

  $𝐻_0$: $\mu_{biosimilar}$/$\mu_{reference}$ ≤ 80% or  $\mu_{biosimilar}$/$\mu_{reference}$ ≥125%

- Alternative hypothesis: the drugs are equivalent

  $𝐻_1$: 80% < $\mu_{biosimilar}$/$\mu_{reference}$ <125%
  
- The equivalence margins 80% and 125% are set by regulators.


Note: We use the geometric mean for 𝜇 because data are skewed (the geometric mean can be approximated using the median)
:::

## Hypothesis test for PK parameters

![](Picture 34.png){width=100%}

## Testing of multiple endpoints

It is often required to investigate equivalence for more than one primary variable. For example, EMA recommends showing equivalence both for AUC and Cmax 

A decision must be made as to whether it is desirable to

- Demonstrate equivalence for <span style="color:red;">all</span> primary endpoints : **most common setting**

  (also known as “multiple co-primary endpoints”)
  
- Demonstrate equivalence for <span style="color:red;">at least one</span> of the primary endpoints
  
  (also known as “multiple primary endpoints”)

::: {style="font-size: 0.5em"}
**Ref**: Sozu T, Sugimoto T, Hamasaki T, Evans SR. Sample Size Determination in Clinical Trials with Multiple Endpoints. Cham: Springer International Publishing; 2015.
:::

## Testing of multiple co-primary endpoints

::: {style="font-size: 0.8em"}
When the trial aims to evaluate the joint effects on **all** of the $m$ <span style="color:red;">co-primary</span> endpoints

- Equivalence has to be shown for all 𝑚 tests
- No multiplicity adjustment is needed to control the type I error rate because all hypotheses have to be rejected
- The <span style="color:red;">type II error rate increases</span> as the number of endpoints to be evaluated increases

    - The power to reject non-equivalence decreases (for a fixed sample size)
    - The probability that the trial will be “successful” decreases (for a fixed sample size)
:::

::: {style="font-size: 0.5em"}
**Ref**: Sozu T, Sugimoto T, Hamasaki T, Evans SR. Sample Size Determination in Clinical Trials with Multiple Endpoints. Cham: Springer International Publishing; 2015.
:::

## Testing of multiple co-primary endpoints

![](Picture 35.png){width=100%}


## Testing of multiple co-primary endpoints

Increase in sample size can be extreme, especially if

- No correlation exists between the test statistics
- Many tests are carried out

One possible solution, if the required sample size is not feasible, is to power the study so that at least k out of m tests have to meet the equivalence criterion

## Testing of multiple primary endpoints

![](Picture 36.png){width=100%}


## Testing of multiple primary endpoints

![](Picture 37.png){width=100%}

## Testing of multiple primary endpoints

![](Picture 38.png){width=100%}


## Testing of multiple primary endpoints

![](Picture 39.png){width=100%}


## Testing of multiple primary endpoints

![](Picture 40.png){width=100%}


## Adaptive trial designs

- Trial specifications are often based on preliminary and/or uncertain information
- Performing a study in a fixed sample size design implies a considerable risk of resulting in a too high or too low sample size.
- It is desirable to terminate the trial when the treatment seems to be ineffective.

## Adaptive trial designs

We can adopt a multi-stage design to

- Recruit a portion of the planned sample
- Recalculate the sample size based on the observed variability (without unblinding treatment allocation)
- Determine whether a test drug is promising enough to warrant further testing

## Adaptive trial designs

Sample size re-estimation in bioequivalence studies inflates the type I error according to

- The required sample size
- The sample size of the internal pilot study
- The standardized equivalence or non-inferiority margin

The elevation of the significance level is negligible for most practical situations.

::: {style="font-size: 0.5em"}
**Ref**: Friede T, Kieser M. Blinded sample size reassessment in non-inferiority and equivalence trials. Statist Med. 2003 Mar 30;22(6):995–1007.
:::

## Simulations for sample size estimation

Empirical sample size estimation through simulation

- Testing for equivalence on (co-)primary endpoints
- Evaluate the decrease in power due to multiple testing 
- Evaluate impact of adaptive design choices
- Empirically assess type I and type II error as a function of sample size and other parameters

::: {style="font-size: 0.5em"}
**Ref**: Mielke J, Jones B, Jilma B, König F. Sample Size for Multiple Hypothesis Testing in Biosimilar Development. Statistics in Biopharmaceutical Research. 2018 Jan 2;10(1):39–49.
:::

## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 41.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 42.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 43.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 44.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 45.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 46.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 47.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 48.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 49.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 50.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 51.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 52.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 53.png){width=100%}


## Example of a phase 1 biosimilar study (NCT01922336)

![](Picture 54.png){width=100%}


# Phase 3 biosimilar trials

![](Picture 55.png){width=100%}


## Clinical Development Plan of Phase 3

![](Picture 56.png){width=100%}


## Clinical Development Plan of Phase 3

Key differences in sample size estimation

::: {style="font-size: 0.7em"}
- Choice of endpoint (preferences may differ between EMA and FDA)
- Data distribution: Normal, Binary, Binomial, etc.
- Choice and justification of equivalence margin (e.g., clinical relevance)
:::

Equivalence should be demonstrated for all (primary) endpoints for all comparisons between the bio-similar and the (EU-sourced and US-sourced) reference drug

## Clinical Development Plan of Phase 3

![](Picture 57.png){width=100%}

## Clinical Development Plan of Phase 3

![](Picture 58.png){width=100%}


## Clinical Development Plan of Phase 3

![](Picture 59.png){width=100%}


# Software for sample size estimation

## Integral Simulation for 2 Treatment Arms & 1 Outcome

A Shiny App

## App’s Structure

1. LANDING PAGE
    
    - A pop-up display to choose sample calculation method. 

2. INPUT PANEL

    - A panel to input parameters needed to calculate the sample. It is changed dynamically depends on the method chosen. 

3. OUTPUT PANEL

    - Displays the result of calculation/simulation with the respective input. 

## Landing Page

![](Picture 60.png){width=100%}


## Input Panel

![](Picture 61.png){width=100%}

## Input Panel (2)

![](Picture 62.png){width=100%}

## Input Panel (3)

![](Picture 63.png){width=100%}

## Output Panel

![](Picture 64.png){width=100%}


## Output Panel

![](Picture 65.png){width=100%}

## Generated Report

![](Picture 66.png){width=100%}


## Generated Report (2)

![](Picture 67.png){width=100%}


# Non-randomized Intervention Studies

## Randomization

![](Picture 68.png){width=100%}


## Limitations of randomized trials

![](Picture 69.png){width=100%}


## Limitations of randomized trials

![](Picture 70.png){width=100%}


## The efficacy-effectiveness gap

![](Picture 71.png){width=100%}

## What is real-world data (RWD)?

![](Picture 72.png){width=100%}

## What is real-world data (RWD)?

Routinely collected data relating to a patient’s health status or the delivery of health care from a variety of sources other than traditional clinical trials

**Primary research data**

- New data collection
- E.g., data collected for an ad hoc study or a prospective patient registry

**Secondary research data**

- Analysis of existing data
- E.g., data from (inter)national databases or electronic healthcare records

## Sources of real-world data

![](Picture 73.png){width=100%}


## Sources of real-world data

**Clinical Practice Research Datalink | CPRD**

The CPRD database contains coded and anonymised EHR data from >2000 primary care practices in UK capturing information on:

- Demographic characteristics
- Diagnoses and symptoms
- Drug exposures
- Vaccination history
- Laboratory tests
- Referrals to hospital and specialist care

## Sources of real-world data

![](Picture 74.png){width=100%}


## Sources of real-world data

![](Picture 75.png){width=100%}


# Real-world Evidence

## What is real-world evidence (RWE)?

- Information derived from the analysis of RWD

    - Observational studies
    - Administrative (e.g., claims) databases
    - Registries
    - Wearable devices
    - …

- Information derived from combining clinical trial data and RWD

    - Incorporation of historical controls
    - Indirect treatment comparisons

## Real-world evidence studies

Well-designed, well-executed, and well reported nonrandomized observational studies are a critical component of the body of evidence

- RWE studies may help to identify how new drugs are utilized and impacted under routine prescribing practice
- Results of RCTs and non-randomised studies do not inevitably differ [ref, ref, ref] 

  (especially if statistical analyse target the same estimands)

- High degree of reproducibility for RWE studies with good methodological transparency [ref]

## Use of real-world evidence

![](Picture 76.png){width=100%}

## RWE from prospective cohort studies

![](Picture 77.png){width=100%}


## RWE from registry-based studies

![](Picture 78.png){width=100%}


## RWE from pragmatic trials

![](Picture 79.png){width=100%}


## Leveraging RWD in clinical trials

Incorporation of historical data during the design and analysis of clinical trials may help to:

- Lower both cost and trial duration
- Facilitate participant recruitment
- Address ethical barriers (e.g. pediatric studies)

## RWE studies – what is the catch?

The analysis of real-world data is prone to various sources of bias.

- The Achilles heel of observational studies is error due to imbalance in unobserved variables

![](Picture 80.png){width=100% fig-align="center"}

## RWE studies – what is the catch?

![](Picture 81.png){width=100%}


## RWE studies – what is the catch?

Missing data

- Key variables and outcomes are not always measured or collected
- Lack of data may be informative
- Right censoring, e.g., loss to follow-up
- Interval censoring, e.g., when observing an AE requires follow-ups or inspections
- Left censoring
- Lack of time zero data (especially when making secondary use of RWD)

## RWE studies – what is the catch?

Heterogeneity

- Routine clinical practice (e.g., treatment options, dosage)
- Variable & outcome definitions
- Visit schedules and patient follow-up
- Quality and completeness of relevant data sources
- Analysis methods [ref] (e.g. when combining data across multiple registries)

## RWE studies – what is the catch?

![](Picture 82.png){width=100%}

## Appraising the quality of RWE

![](Picture 83.png){width=100%}